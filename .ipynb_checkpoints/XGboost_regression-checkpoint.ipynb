{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import scipy\n",
    "import numpy as np\n",
    "import nltk #from nltk.tokenize import punkt #.tokenize.moses import MosesTokenizer\n",
    "from gensim.models import KeyedVectors\n",
    "from itertools import islice\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import json\n",
    "import pickle\n",
    "from cyordereddict import OrderedDict\n",
    "from joblib import Parallel, delayed\n",
    "pattern = re.compile(r'[^\\s\\w_]+')\n",
    "\n",
    "DATASET_FILE_PATH = \"./DataSet/yelp.csv/yelp.csv\"\n",
    "WORD2VEC_FILE_PATH = \"./DataSet/FBword2vec/wiki.en.vec\"\n",
    "TRAINING_DATA_PATH = \"./DataSet/trainingData\"\n",
    "EXTENDED_DATASET_PATH = \"./DataSet/review.json\"\n",
    "\n",
    "###File Names\n",
    "TEST_NAME = \"standard_tokenizer_withStopwords_noPunctuation_FB_vectors_100percentDataset\"\n",
    "\n",
    "EMBEDDED_MATRIX_NAME = TEST_NAME+'_embedded_matrix.pkl'\n",
    "TOKENIZED_SENTENCES_NAME = TEST_NAME+ \"_tokenized_sentences.pkl\"\n",
    "WORD_INDEX_NAME = TEST_NAME+ \"_word_index.pkl\"\n",
    "INDEXED_TOKENIZED_SENTENCES_NAME = TEST_NAME + \"_indexed_tokenized_sentences.pkl\"\n",
    "\n",
    "LABELS_NAME = 'labels.pkl'\n",
    "\n",
    "\n",
    "AMOUNT_OF_WORDS = 70\n",
    "FACEBOOK_EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = pickle.load(open(WORD_INDEX_NAME,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_matrix =  np.load(EMBEDDED_MATRIX_NAME+'.npy')\n",
    "print('embedded matrix loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexed_tokenized_sentences = pickle.load(open(INDEXED_TOKENIZED_SENTENCES_NAME,'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshapeSentences(indexed_tokenized_sentences,sentence_length):\n",
    "    for i in range(len(indexed_tokenized_sentences)):\n",
    "        padding = sentence_length - len(indexed_tokenized_sentences[i])\n",
    "        indexed_tokenized_sentences[i] = indexed_tokenized_sentences[i][:sentence_length] + [-1]*padding\n",
    "    return indexed_tokenized_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### BUILDING MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reshaped_Sentences = reshapeSentences(indexed_tokenized_sentences, AMOUNT_OF_WORDS)\n",
    "reshaped_Sentences = np.stack(reshaped_Sentences,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_pickle(\"labels.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import sklearn.datasets\n",
    "import sklearn.metrics\n",
    "import sklearn.feature_selection\n",
    "import sklearn.feature_extraction\n",
    "import sklearn.cross_validation\n",
    "import sklearn.model_selection\n",
    "import tqdm\n",
    "# fix random seed for reproducibility\n",
    "seed = 42\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embedding(index_array, embedding_matrix):\n",
    "    samples = index_array.shape[0]\n",
    "    components = index_array.shape[1]*FACEBOOK_EMBEDDING_SIZE\n",
    "    embedding = np.zeros((samples,components))\n",
    "    for i in range(samples):\n",
    "        for j in range(components):\n",
    "            embedding[i][j:j+FACEBOOK_EMBEDDING_SIZE] = embedding_matrix[index_array[i,j]]\n",
    "    return embedding\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(reshaped_Sentences, labels.values, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = np.array([[1,1,1],[2,2,2],[4,5,6]])\n",
    "embedding(test, embedded_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_sizebatch_si  = 50\n",
    "iterations = 25\n",
    "model = None\n",
    "for i in range(iterations):\n",
    "    for start in range(0, len(X_train), batch_size):\n",
    "        model = xgb.train({\n",
    "            'learning_rate': 0.007,\n",
    "            'update':'refresh',\n",
    "            'process_type': 'update',\n",
    "            'refresh_leaf': True,\n",
    "            #'reg_lambda': 3,  # L2\n",
    "            'reg_alpha': 3,  # L1\n",
    "            'silent': False,\n",
    "        }, dtrain=xgb.DMatrix(embedding(X_train[start:start+batch_size],embedding_matrix), y_train[start:start+batch_size]), xgb_model=model)\n",
    "\n",
    "        y_pr = model.predict(xgb.DMatrix(embedding(X_test,embedding_matrix))\n",
    "        #print('    MSE itr@{}: {}'.format(int(start/batch_size), sklearn.metrics.mean_squared_error(y_test, y_pr)))\n",
    "    print('MSE itr@{}: {}'.format(i, sklearn.metrics.mean_squared_error(y_test, y_pr)))\n",
    "\n",
    "y_pr = model.predict(xgb.DMatrix(X_test))\n",
    "print('MSE at the end: {}'.format(sklearn.metrics.mean_squared_error(y_test, y_pr)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
